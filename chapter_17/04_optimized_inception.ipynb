{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## How to Implement the Inception Module\n",
        "The inception module was described and used in the GoogLeNet model in the 2015 paper by\n",
        "Christian Szegedy, et al. titled Going Deeper with Convolutions (introduced in Chapter 15).\n",
        "Like the VGG model, the GoogLeNet model achieved top results in the 2014 version of the\n",
        "ILSVRC challenge. The key innovation on the inception model is called the inception module.\n",
        "This is a block of parallel convolutional layers with different sized filters (e.g. 1 x 1, 3 x 3, 5 x 5)\n",
        "and a 3 x 3 max pooling layer, the results of which are then concatenated.\n",
        "\n",
        "This is a very simple and powerful architectural unit that allows the model to learn not only\n",
        "parallel filters of the same size, but parallel filters of differing sizes, allowing learning at multiple\n",
        "scales. We can implement an inception module directly using the Keras functional API. The\n",
        "function below will create a single inception module with a specified number of filters for each\n",
        "of the parallel convolutional layers. From the GoogLeNet architecture described in the paper, it\n",
        "does not appear to use a systematic number of filters for parallel convolutional layers as the\n",
        "model is highly optimized. As such, we can parameterize the module definition so that we can\n",
        "specify the number of filters to use in each of the 1 x 1, 3 x 3, and 5 x 5 filters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you intend to use many inception modules in your model, you may require this computational performance-based modification. The function below implements this optimization\n",
        "improvement with parameterization so that you can control the amount of reduction in the\n",
        "number of filters prior to the 3 x 3 and 5 x 5 convolutional layers and the number of increased\n",
        "filters after max pooling.\n",
        "\n",
        "\n",
        "We can create a model with two of these optimized inception modules to get a concrete idea\n",
        "of how the architecture looks in practice."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# example of creating a CNN with an efficient inception module\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.utils import plot_model\n",
        "\n",
        "# function for creating a projected inception module\n",
        "def inception_module(layer_in, f1, f2_in, f2_out, f3_in, f3_out, f4_out):\n",
        "\t# 1x1 conv\n",
        "\tconv1 = Conv2D(f1, (1,1), padding='same', activation='relu')(layer_in)\n",
        "\t# 3x3 conv\n",
        "\tconv3 = Conv2D(f2_in, (1,1), padding='same', activation='relu')(layer_in)\n",
        "\tconv3 = Conv2D(f2_out, (3,3), padding='same', activation='relu')(conv3)\n",
        "\t# 5x5 conv\n",
        "\tconv5 = Conv2D(f3_in, (1,1), padding='same', activation='relu')(layer_in)\n",
        "\tconv5 = Conv2D(f3_out, (5,5), padding='same', activation='relu')(conv5)\n",
        "\t# 3x3 max pooling\n",
        "\tpool = MaxPooling2D((3,3), strides=(1,1), padding='same')(layer_in)\n",
        "\tpool = Conv2D(f4_out, (1,1), padding='same', activation='relu')(pool)\n",
        "\t# concatenate filters, assumes filters/channels last\n",
        "\tlayer_out = concatenate([conv1, conv3, conv5, pool], axis=-1)\n",
        "\treturn layer_out\n",
        "\n",
        "# define model input\n",
        "visible = Input(shape=(256, 256, 3))\n",
        "# add inception block 1\n",
        "layer = inception_module(visible, 64, 96, 128, 16, 32, 32)\n",
        "# add inception block 1\n",
        "layer = inception_module(layer, 128, 128, 192, 32, 96, 64)\n",
        "# create model\n",
        "model = Model(inputs=visible, outputs=layer)\n",
        "# summarize model\n",
        "model.summary()\n",
        "# plot model architecture\n",
        "plot_model(model, show_shapes=True, to_file='/tmp/inception_module.png')"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Running the example creates a linear summary of the layers that does not really help to\n",
        "understand what is going on. The output is omitted here for brevity. A plot of the model\n",
        "architecture is created that does make the layout of each module clear and how the first model\n",
        "feeds the second module. Note that the first 1 x 1 convolution in each inception module is on\n",
        "the far right for space reasons, but besides that, the other layers are organized left to right\n",
        "within each module"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}