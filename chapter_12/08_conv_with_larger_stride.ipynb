{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Downsample Input With Stride\n",
        "The filter is moved across the image left to right, top to bottom, with a one-pixel column change\n",
        "on the horizontal movements, then a one-pixel row change on the vertical movements. The12.6. Downsample Input With Stride 130\n",
        "amount of movement between applications of the filter to the input image is referred to as the\n",
        "stride, and it is almost always symmetrical in height and width dimensions. The default stride\n",
        "or strides in two dimensions is (1,1) for the height and the width movement, performed when\n",
        "needed. And this default works well in most cases. The stride can be changed, which has an\n",
        "effect both on how the filter is applied to the image and, in turn, the size of the resulting feature\n",
        "map.\n",
        "\n",
        "For example, the stride can be changed to (2,2). This has the effect of moving the filter\n",
        "two pixels left for each horizontal movement of the filter and two pixels down for each vertical\n",
        "movement of the filter when creating the feature map. We can demonstrate this with an example\n",
        "using the 8 X 8 image with a vertical line (left) dot product (. operator) with the vertical line\n",
        "filter (right) with a stride of two pixels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that there are only three valid applications of the 3 X 3 filters to the 8 X 8 input\n",
        "image with a stride of two. This will be the same in the vertical dimension. This has the effect\n",
        "of applying the filter in such a way that the normal feature map output (6 X 6) is down-sampled\n",
        "so that the size of each dimension is reduced by half (3 X 3), resulting in 1 4 the number of\n",
        "pixels (36 pixels down to 9). The stride can be specified in Keras on the Conv2D layer via the\n",
        "stride argument and specified as a tuple with height and width. The example demonstrates\n",
        "the application of our manual vertical line filter on the 8 X 8 input image with a convolutional\n",
        "layer that has a stride of two."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# example of vertical line filter with a stride of 2\n",
        "from numpy import asarray\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "# define input data\n",
        "data = [[0, 0, 0, 1, 1, 0, 0, 0],\n",
        "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
        "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
        "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
        "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
        "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
        "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
        "\t\t[0, 0, 0, 1, 1, 0, 0, 0]]\n",
        "data = asarray(data)\n",
        "data = data.reshape(1, 8, 8, 1)\n",
        "# create model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(1, (3,3), strides=(2, 2), input_shape=(8, 8, 1)))\n",
        "# summarize model\n",
        "model.summary()\n",
        "# define a vertical line detector\n",
        "detector = [[[[0]],[[1]],[[0]]],\n",
        "            [[[0]],[[1]],[[0]]],\n",
        "            [[[0]],[[1]],[[0]]]]\n",
        "weights = [asarray(detector), asarray([0.0])]\n",
        "# store the weights in the model\n",
        "model.set_weights(weights)\n",
        "# apply filter to input data\n",
        "yhat = model.predict(data)\n",
        "# enumerate rows\n",
        "for r in range(yhat.shape[1]):\n",
        "\t# print each column in the row\n",
        "\tprint([yhat[0,r,c,0] for c in range(yhat.shape[2])])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Running the example, we can see from the summary of the model that the shape of the\n",
        "output feature map will be 3 X 3. Applying the handcrafted filter to the input image and\n",
        "printing the resulting activation feature map, we can see that, indeed, the filter still detected\n",
        "the vertical line, and can represent this finding with less information. Downsampling may be\n",
        "desirable in some cases where deeper knowledge of the filters used in the model or of the model\n",
        "architecture allows for some compression in the resulting feature maps."
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}