{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Effect of Filter Size (Kernel Size)\n",
        "Different sized filters will detect different sized features in the input image and, in turn, will\n",
        "result in differently sized feature maps. It is common to use 3 X 3 sized filters, and perhaps\n",
        "5 X 5 or even 7 X 7 sized filters, for larger input images. For example, below is an example of\n",
        "the model with a single filter updated to use a filter size of 8 X 8 pixels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# example of a convolutional layer\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "# create model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(1, (8,8), input_shape=(8, 8, 1)))\n",
        "# summarize model\n",
        "model.summary()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Running the example, we can see that, as you might expect, there is one filter weight for\n",
        "each pixel in the input image (64 + 1 for the bias) and that the output is a feature map with a\n",
        "single pixel"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}