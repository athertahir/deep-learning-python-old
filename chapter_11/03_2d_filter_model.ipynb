{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example of 2D Convolutional Layer\n",
        "We can expand the bump detection example in the previous section to a vertical line detector in\n",
        "a two-dimensional image. Again, we can constrain the input, in this case to a square 8 X 8 pixel\n",
        "input image with a single channel (e.g. grayscale) with a single vertical line in the middle.\n",
        "\n",
        "\n",
        "[0, 0, 0, 1, 1, 0, 0, 0]\n",
        "\n",
        "[0, 0, 0, 1, 1, 0, 0, 0]\n",
        "\n",
        "[0, 0, 0, 1, 1, 0, 0, 0]\n",
        "\n",
        "[0, 0, 0, 1, 1, 0, 0, 0]\n",
        "\n",
        "[0, 0, 0, 1, 1, 0, 0, 0]\n",
        "\n",
        "[0, 0, 0, 1, 1, 0, 0, 0]\n",
        "\n",
        "[0, 0, 0, 1, 1, 0, 0, 0]\n",
        "\n",
        "[0, 0, 0, 1, 1, 0, 0, 0]\n",
        "\n",
        "\n",
        "The input to a Conv2D layer must be four-dimensional. The first dimension defines the\n",
        "samples; in this case, there is only a single sample. The second dimension defines the number of\n",
        "rows; in this case, eight. The third dimension defines the number of columns, again eight in this\n",
        "case, and finally the number of channels, which is one in this case. Therefore, the input must\n",
        "have the four-dimensional shape [samples, columns, rows, channels] or [1, 8, 8, 1] in\n",
        "this case."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will define the Conv2D layer with a single filter as we did in the previous section with\n",
        "the Conv1D example. The filter will be two-dimensional and square with the shape 3 X 3. The\n",
        "layer will expect input samples to have the shape [columns, rows, channels] or [8,8,1]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# example of calculation 2d convolutions\n",
        "from numpy import asarray\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "# define input data\n",
        "data = [[0, 0, 0, 1, 1, 0, 0, 0],\n",
        "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
        "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
        "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
        "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
        "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
        "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
        "\t\t[0, 0, 0, 1, 1, 0, 0, 0]]\n",
        "data = asarray(data)\n",
        "data = data.reshape(1, 8, 8, 1)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will define a vertical line detector filter to detect the single vertical line in our input\n",
        "data. The filter looks as follows:\n",
        "\n",
        "0, 1, 0\n",
        "\n",
        "0, 1, 0\n",
        "\n",
        "0, 1, 0\n",
        "\n",
        "Finally, we will apply the filter to the input image, which will result in a feature map that\n",
        "we would expect to show the detection of the vertical line in the input image.\n",
        "\n",
        "The shape of the feature map output will be four-dimensional with the shape [batch, rows,\n",
        "columns, filters]. We will be performing a single batch and we have a single filter (one filter\n",
        "and one input channel), therefore the output or feature map shape is [1, 6, 6, 1]. We can\n",
        "pretty-print the content of the single feature map as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# create model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(1, (3,3), input_shape=(8, 8, 1)))\n",
        "# define a vertical line detector\n",
        "detector = [[[[0]],[[1]],[[0]]],\n",
        "            [[[0]],[[1]],[[0]]],\n",
        "            [[[0]],[[1]],[[0]]]]\n",
        "weights = [asarray(detector), asarray([0.0])]\n",
        "# store the weights in the model\n",
        "model.set_weights(weights)\n",
        "# confirm they were stored\n",
        "print(model.get_weights())\n",
        "# apply filter to input data\n",
        "yhat = model.predict(data)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The shape of the feature map output will be four-dimensional with the shape [batch, rows,\n",
        "columns, filters]. We will be performing a single batch and we have a single filter (one filter\n",
        "and one input channel), therefore the output or feature map shape is [1, 6, 6, 1]. We can\n",
        "pretty-print the content of the single feature map as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for r in range(yhat.shape[1]):\n",
        "\t# print each column in the row\n",
        "\tprint([yhat[0,r,c,0] for c in range(yhat.shape[2])])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Running the example first confirms that the handcrafted filter was correctly defined in the\n",
        "layer weights. Next, the calculated feature map is printed. We can see from the scale of the\n",
        "numbers that indeed the filter has detected the single vertical line with strong activation in the\n",
        "middle of the feature map."
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}